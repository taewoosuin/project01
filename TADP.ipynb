{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ed1WX84Oe37e",
        "o-D6VTRP4k1P",
        "GBL9KpAt5MDA"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#사전 작업"
      ],
      "metadata": {
        "id": "ed1WX84Oe37e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysWrrU0Le2WD",
        "outputId": "f260905f-d15e-4f33-cf06-2120068e790c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y fonts-nanum*\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SMmLqkze3SL",
        "outputId": "2a56aeb4-eb0a-477e-abe2-b79a5c82a6f0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Note, selecting 'fonts-nanum-extra' for glob 'fonts-nanum*'\n",
            "Note, selecting 'fonts-nanum-coding' for glob 'fonts-nanum*'\n",
            "Note, selecting 'fonts-nanum-eco' for glob 'fonts-nanum*'\n",
            "Note, selecting 'fonts-nanum' for glob 'fonts-nanum*'\n",
            "The following NEW packages will be installed:\n",
            "  fonts-nanum fonts-nanum-coding fonts-nanum-eco fonts-nanum-extra\n",
            "0 upgraded, 4 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 46.0 MB of archives.\n",
            "After this operation, 177 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-nanum all 20200506-1 [10.3 MB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-nanum-coding all 2.5-3 [4,988 B]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-nanum-eco all 1.000-7 [14.7 MB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-nanum-extra all 20200506-1 [21.0 MB]\n",
            "Fetched 46.0 MB in 2s (18.5 MB/s)\n",
            "Selecting previously unselected package fonts-nanum.\n",
            "(Reading database ... 121749 files and directories currently installed.)\n",
            "Preparing to unpack .../fonts-nanum_20200506-1_all.deb ...\n",
            "Unpacking fonts-nanum (20200506-1) ...\n",
            "Selecting previously unselected package fonts-nanum-coding.\n",
            "Preparing to unpack .../fonts-nanum-coding_2.5-3_all.deb ...\n",
            "Unpacking fonts-nanum-coding (2.5-3) ...\n",
            "Selecting previously unselected package fonts-nanum-eco.\n",
            "Preparing to unpack .../fonts-nanum-eco_1.000-7_all.deb ...\n",
            "Unpacking fonts-nanum-eco (1.000-7) ...\n",
            "Selecting previously unselected package fonts-nanum-extra.\n",
            "Preparing to unpack .../fonts-nanum-extra_20200506-1_all.deb ...\n",
            "Unpacking fonts-nanum-extra (20200506-1) ...\n",
            "Setting up fonts-nanum-extra (20200506-1) ...\n",
            "Setting up fonts-nanum (20200506-1) ...\n",
            "Setting up fonts-nanum-coding (2.5-3) ...\n",
            "Setting up fonts-nanum-eco (1.000-7) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n",
            "/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs\n",
            "/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/nanum: caching, new cache contents: 39 fonts, 0 dirs\n",
            "/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n",
            "/root/.local/share/fonts: skipping, no such directory\n",
            "/root/.fonts: skipping, no such directory\n",
            "/usr/share/fonts/truetype: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/humor-sans: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/liberation: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/nanum: skipping, looped directory detected\n",
            "/var/cache/fontconfig: cleaning cache directory\n",
            "/root/.cache/fontconfig: not cleaning non-existent cache directory\n",
            "/root/.fontconfig: not cleaning non-existent cache directory\n",
            "fc-cache: succeeded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#데이터 전처리\n"
      ],
      "metadata": {
        "id": "yHE-2bvoe8qf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UcgExl3dNjB9"
      },
      "outputs": [],
      "source": [
        "#import 및 파일 불러오기\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from scipy import stats\n",
        "\n",
        "plt.rc('font', family='NanumGothic')\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/Colab Notebooks/01 DATA/accidentInfoList.CSV\"\n",
        "df = pd.read_csv(file_path, encoding='cp949')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 숫자 추출 함수 생성\n",
        "def extract_numbers_from_age(age):\n",
        "    numbers = re.findall(r'\\d+', str(age))\n",
        "    if numbers:\n",
        "        return int(numbers[0])\n",
        "    else:\n",
        "        return np.nan\n",
        "\n",
        "# 문자 데이터 제거 및 숫자만 추출\n",
        "df['가해운전자 연령'] = df['가해운전자 연령'].apply(extract_numbers_from_age)\n",
        "df['피해운전자 연령'] = df['피해운전자 연령'].apply(extract_numbers_from_age)\n",
        "mean_age_driver = round(df['가해운전자 연령'].mean(), 1)\n",
        "mean_age_victim = round(df['피해운전자 연령'].mean(), 1)\n",
        "\n",
        "# 결측치 처리\n",
        "df['가해운전자 연령'].fillna(mean_age_driver, inplace=True)\n",
        "df['피해운전자 연령'].fillna(mean_age_victim, inplace=True)\n",
        "df['피해운전자 차종'].fillna('NaN', inplace=True)\n",
        "df['피해운전자 성별'].fillna('NaN', inplace=True)\n",
        "df['피해운전자 상해정도'].fillna('상해없음', inplace=True)\n"
      ],
      "metadata": {
        "id": "sE6suEWSAUr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 피쳐 생성\n",
        "df['ECLO'] = df['사망자수'] * 10 + df['중상자수'] * 5 + df['경상자수'] * 3 + df['부상신고자수'] * 1\n",
        "\n",
        "# '사고일시' 열에서 시간 정보 추출\n",
        "df['사고일시'] = pd.to_datetime(df['사고일시'], format='%Y년 %m월 %d일 %H시')\n",
        "df['사고발생시간'] = df['사고일시'].dt.hour"
      ],
      "metadata": {
        "id": "mNBXVK6E4FfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#원핫 인코딩\n",
        "categorical_features = ['요일']\n",
        "encoded_df = pd.get_dummies(df[categorical_features])\n",
        "df = df.drop(columns=categorical_features)\n",
        "df = pd.concat([df, encoded_df], axis=1)"
      ],
      "metadata": {
        "id": "BX5BuswHAwif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#시각화 자료 준비"
      ],
      "metadata": {
        "id": "o-D6VTRP4k1P"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J1MW7-914onj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#모델링"
      ],
      "metadata": {
        "id": "90u27H-I4lFG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 피처 선택\n",
        "features = ['요일_일요일', '요일_토요일', '가해운전자 연령', '피해운전자 연령']\n",
        "\n",
        "# 독립변수와 종속변수 분할\n",
        "X = df[features]\n",
        "y = df['ECLO']\n",
        "\n",
        "# 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 이상치 제거\n",
        "z_scores = np.abs(stats.zscore(df['ECLO']))\n",
        "outliers = (z_scores > 3)\n",
        "df_no_outliers = df[~outliers]\n",
        "\n",
        "# 독립변수와 종속변수 다시 설정\n",
        "X_no_outliers = df_no_outliers[features]\n",
        "y_no_outliers = df_no_outliers['ECLO']\n",
        "\n",
        "# 데이터 분할\n",
        "X_train_no_outliers, X_test_no_outliers, y_train_no_outliers, y_test_no_outliers = train_test_split(X_no_outliers, y_no_outliers, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "vtp1USKqAiNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 생성 및 훈련\n",
        "model = RandomForestRegressor(random_state=42)\n",
        "model.fit(X_train_no_outliers, y_train_no_outliers)\n",
        "\n",
        "# 모델 평가\n",
        "y_pred = model.predict(X_test_no_outliers)\n",
        "mse = mean_squared_error(y_test_no_outliers, y_pred)\n",
        "mae = mean_absolute_error(y_test_no_outliers, y_pred)\n",
        "r2 = r2_score(y_test_no_outliers, y_pred)\n",
        "\n",
        "print(\"Mean Squared Error without outliers:\", mse)\n",
        "print(\"Mean Absolute Error without outliers:\", mae)\n",
        "print(\"R² Score without outliers:\", r2)\n",
        "\n",
        "# 중요도 확인\n",
        "feature_importances = model.feature_importances_\n",
        "feature_importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances})\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "print(feature_importance_df)"
      ],
      "metadata": {
        "id": "J6rjWvTY4sUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SUB"
      ],
      "metadata": {
        "id": "GBL9KpAt5MDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns.tolist())"
      ],
      "metadata": {
        "id": "AeJW7KhEflRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#임시 저장\n",
        "output_file_path = \"/content/drive/MyDrive/Colab Notebooks/01 DATA/modified_accidentInfoList.csv\"\n",
        "df.to_csv(output_file_path, index=False)"
      ],
      "metadata": {
        "id": "4e-ObWKhfoo2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}